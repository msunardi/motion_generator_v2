_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_14 (GRU)                 (50, 50, 64)              12672     
_________________________________________________________________
gru_15 (GRU)                 (50, 50, 128)             74112     
_________________________________________________________________
gru_16 (GRU)                 (50, 50, 256)             295680    
_________________________________________________________________
dense_7 (Dense)              (50, 50, 2)               514       
=================================================================
Total params: 382,978
Trainable params: 382,978
Non-trainable params: 0
_________________________________________________________________
None
Train on 21900 samples, validate on 2700 samples
Epoch 1/10
21900/21900 [==============================] - 160s 7ms/step - loss: 0.6817 - acc: 0.5691 - val_loss: 0.6589 - val_acc: 0.6102
Epoch 2/10
21900/21900 [==============================] - 140s 6ms/step - loss: 0.6613 - acc: 0.6104 - val_loss: 0.6494 - val_acc: 0.6297
Epoch 3/10
21900/21900 [==============================] - 176s 8ms/step - loss: 0.6501 - acc: 0.6244 - val_loss: 0.6278 - val_acc: 0.6491
Epoch 4/10
21900/21900 [==============================] - 158s 7ms/step - loss: 0.5814 - acc: 0.6856 - val_loss: 0.4403 - val_acc: 0.7818
Epoch 5/10
21900/21900 [==============================] - 152s 7ms/step - loss: 0.3548 - acc: 0.8336 - val_loss: 0.3175 - val_acc: 0.8407
Epoch 6/10
21900/21900 [==============================] - 170s 8ms/step - loss: 0.2685 - acc: 0.8779 - val_loss: 0.3258 - val_acc: 0.8443
Epoch 7/10
21900/21900 [==============================] - 191s 9ms/step - loss: 0.2353 - acc: 0.8933 - val_loss: 0.2085 - val_acc: 0.9071
Epoch 8/10
21900/21900 [==============================] - 194s 9ms/step - loss: 0.2159 - acc: 0.9026 - val_loss: 0.2216 - val_acc: 0.9031
Epoch 9/10
21900/21900 [==============================] - 199s 9ms/step - loss: 0.2037 - acc: 0.9087 - val_loss: 0.1921 - val_acc: 0.9128
Epoch 10/10
21900/21900 [==============================] - 206s 9ms/step - loss: 0.1952 - acc: 0.9122 - val_loss: 0.1759 - val_acc: 0.9210
sample  actual          predicted                       prediction error (over correct class)
0       0       [0.9893573  0.01064272]         0.010642707347869873
1       1       [0.03534756 0.9646524 ]         0.035347580909729004
2       1       [0.00124171 0.9987583 ]         0.0012416839599609375
3       1       [0.78175163 0.2182484 ]         **0.7817516028881073**
4       1       [0.0018296 0.9981704]   0.0018296241760253906
5       0       [0.98846775 0.01153224]         0.011532247066497803
6       1       [0.00579505 0.99420494]         0.0057950615882873535
7       1       [0.00754822 0.9924517 ]         0.007548272609710693
8       0       [0.992508   0.00749206]         0.007492005825042725
9       1       [0.00251472 0.9974853 ]         0.0025147199630737305
10      1       [0.00245767 0.9975424 ]         0.0024576187133789062
11      1       [0.00412897 0.995871  ]         0.004128992557525635
12      0       [0.9980684 0.0019316]   0.001931607723236084
13      1       [0.01238959 0.98761046]         0.012389540672302246
14      0       [0.9741252 0.0258748]   0.025874793529510498
15      1       [0.00416819 0.9958318 ]         0.004168212413787842
16      0       [0.9932151  0.00678497]         0.006784915924072266
17      0       [0.995961   0.00403902]         0.004038989543914795
18      0       [0.9971507 0.0028493]   0.002849280834197998
19      1       [0.00227936 0.99772066]         0.002279341220855713
20      1       [0.00166616 0.9983339 ]         0.0016661286354064941
21      1       [0.00227134 0.99772865]         0.0022713541984558105
22      0       [0.97379285 0.02620712]         0.026207149028778076
23      0       [0.98685384 0.01314615]         0.013146162033081055
24      1       [0.01264198 0.9873581 ]         0.01264190673828125
25      0       [0.9947582  0.00524177]         0.005241811275482178
26      0       [0.9792549 0.0207451]   0.02074509859085083
27      1       [0.00167277 0.9983272 ]         0.0016728043556213379
28      1       [0.01905353 0.9809465 ]         0.019053518772125244
29      1       [0.00336289 0.9966371 ]         0.003362894058227539
30      1       [0.00306714 0.99693286]         0.0030671358108520508
31      1       [0.00771223 0.99228776]         0.007712244987487793
32      0       [0.94698596 0.05301403]         0.05301403999328613
33      1       [0.00225576 0.9977443 ]         0.002255678176879883
34      1       [0.00239635 0.9976037 ]         0.0023962855339050293
35      0       [0.99292254 0.00707742]         0.007077455520629883
36      1       [0.02484465 0.97515535]         0.024844646453857422
37      1       [0.00269743 0.99730253]         0.002697467803955078
38      0       [0.8431636  0.15683632]         0.1568363904953003
39      1       [0.00885152 0.9911485 ]         0.00885152816772461
40      1       [0.00851942 0.9914806 ]         0.008519411087036133
41      0       [0.9872479  0.01275214]         0.012752115726470947
42      0       [0.9864667  0.01353332]         0.013533294200897217
43      1       [0.00189656 0.9981034 ]         0.0018966197967529297
44      0       [0.99721473 0.00278528]         0.0027852654457092285
45      1       [0.00452829 0.9954717 ]         0.0045282840728759766
46      0       [0.99211323 0.00788679]         0.007886767387390137
47      1       [0.01812387 0.9818762 ]         0.0181238055229187
48      1       [0.1295942 0.8704058]   0.12959420680999756
49      0       [0.95045644 0.04954356]         0.049543559551239014

================

Confusion matrix

================

        P       N
P       29      1
N       0       20
Precision: 1.0
Recall: 0.9666666666666667

TensorBoard event: 20180215_083157

# TEST2
sample  actual          predicted                       prediction error (over correct class)
0       0       [0.9965335  0.00346648]         0.003466486930847168
1       1       [0.00581228 0.9941877 ]         0.005812287330627441
2       0       [0.9824682  0.01753188]         0.01753181219100952
3       0       [0.9979304  0.00206957]         0.0020695924758911133
4       1       [0.01543607 0.98456395]         0.015436053276062012
5       1       [0.00276744 0.9972326 ]         0.0027673840522766113
6       1       [0.23866268 0.76133734]         0.23866266012191772
7       0       [0.8509998  0.14900021]         0.14900022745132446
8       1       [0.00380843 0.9961915 ]         0.0038084983825683594
9       0       [0.9796882  0.02031175]         0.02031177282333374
10      1       [0.00176821 0.9982318 ]         0.0017681717872619629
11      1       [0.01924623 0.98075384]         0.019246160984039307
12      0       [0.9984231  0.00157686]         0.0015769004821777344
13      1       [0.00576501 0.994235  ]         0.005765020847320557
14      1       [0.2564467  0.74355334]         0.2564466595649719
15      0       [0.9868919  0.01310807]         0.01310807466506958
16      0       [0.99490887 0.00509109]         0.00509113073348999
17      0       [0.9831722  0.01682779]         0.016827821731567383
18      1       [0.00633118 0.99366885]         0.006331145763397217
19      0       [0.9974982  0.00250175]         0.0025017857551574707
20      1       [0.00156062 0.9984394 ]         0.0015606284141540527
21      1       [0.00271089 0.9972892 ]         0.0027108192443847656
22      1       [0.00233129 0.9976687 ]         0.0023313164710998535
23      0       [0.9753635  0.02463654]         0.024636507034301758
24      0       [0.99780685 0.0021932 ]         0.002193152904510498
25      0       [0.9969806  0.00301932]         0.003019392490386963
26      1       [0.00365384 0.9963462 ]         0.0036538243293762207
27      0       [0.71739626 0.2826037 ]         0.28260374069213867
28      0       [0.9970245  0.00297549]         0.0029755234718322754
29      0       [0.99410385 0.00589616]         0.005896151065826416
30      1       [0.0054575 0.9945425]   0.005457520484924316
31      1       [0.00242881 0.9975712 ]         0.0024288296699523926
32      1       [0.00825089 0.99174917]         0.008250832557678223
33      0       [0.9960582  0.00394178]         0.003941774368286133
34      0       [0.9716552  0.02834488]         0.028344810009002686
35      1       [0.00131643 0.9986835 ]         0.0013164877891540527
36      1       [0.00170974 0.99829024]         0.00170975923538208
37      1       [0.00229422 0.99770576]         0.0022942423820495605
38      1       [0.00223481 0.9977652 ]         0.002234816551208496
39      0       [0.99495924 0.00504069]         0.005040764808654785
40      1       [0.01404215 0.9859578 ]         0.014042198657989502
41      1       [0.00814811 0.99185187]         0.008148133754730225
42      0       [0.90968406 0.09031594]         0.09031593799591064
43      1       [0.03760462 0.9623954 ]         0.037604570388793945Precision: 1.0
Recall: 0.9666666666666667
44      1       [0.00238226 0.99761766]         0.002382338047027588
45      1       [0.00264727 0.9973527 ]         0.0026472806930541992
46      0       [0.9957255  0.00427453]         0.004274487495422363
47      1       [0.00338499 0.996615  ]         0.003385007381439209
48      0       [0.96749294 0.03250702]         0.03250706195831299
49      0       [0.8784295  0.12157057]         0.12157052755355835

================

Confusion matrix

================

        P       N
P       27      0
N       0       23
Precision: 1.0
Recall: 1.0

# TEST3

sample  actual          predicted                       prediction error (over correct class)
0       1       [0.04278146 0.9572186 ]         0.04278141260147095
1       1       [0.01328287 0.9867171 ]         0.0132828950881958
2       0       [0.82499987 0.17500015]         0.1750001311302185
3       1       [0.10847665 0.89152336]         0.10847663879394531
4       1       [0.00259198 0.997408  ]         0.002592027187347412
5       0       [0.7565097  0.24349028]         0.2434902787208557
6       1       [0.01145647 0.9885435 ]         0.011456489562988281
7       1       [0.00774311 0.9922569 ]         0.007743120193481445
8       0       [0.99675757 0.00324241]         0.0032424330711364746
9       1       [0.00544968 0.9945503 ]         0.00544971227645874
10      1       [0.00177888 0.9982211 ]         0.0017789006233215332
11      1       [0.5885399 0.4114601]   **0.5885398983955383**
12      1       [0.00134659 0.9986534 ]         0.001346588134765625
13      1       [0.00398047 0.99601954]         0.003980457782745361
14      0       [0.9952082  0.00479183]         0.0047917962074279785
15      0       [0.99127406 0.00872596]         0.008725941181182861
16      1       [0.00267982 0.99732023]         0.002679765224456787
17      0       [0.94017786 0.05982221]         0.059822142124176025
18      0       [0.9953507 0.0046493]   0.0046492815017700195
19      1       [0.6787216  0.32127845]         **0.67872154712677**
20      0       [0.99244237 0.0075577 ]         0.00755763053894043
21      1       [0.00532258 0.9946774 ]         0.005322575569152832
22      0       [0.31836954 0.6816305 ]         **0.6816304624080658**
23      0       [0.99694914 0.00305088]         0.003050863742828369
24      1       [0.7309089  0.26909116]         **0.7309088408946991**
25      1       [0.0018416 0.9981584]   0.0018416047096252441
26      0       [0.99409544 0.00590449]         0.005904555320739746
27      0       [0.99224263 0.00775737]         0.007757365703582764
28      1       [0.00590349 0.9940965 ]         0.005903482437133789
29      1       [0.01687277 0.98312724]         0.016872763633728027
30      0       [0.99433595 0.00566404]         0.005664050579071045
31      1       [0.00178204 0.9982179 ]         0.0017821192741394043
32      1       [0.00311285 0.99688715]         0.0031128525733947754
33      1       [0.00257541 0.9974246 ]         0.002575397491455078
34      1       [0.82830167 0.1716983 ]         **0.8283016979694366**
35      1       [0.06215369 0.93784636]         0.062153637409210205
36      1       [0.03294578 0.9670542 ]         0.03294581174850464
37      1       [0.00162632 0.9983736 ]         0.0016263723373413086
38      1       [0.00220962 0.99779034]         0.0022096633911132812
39      0       [0.98924387 0.01075618]         0.010756134986877441
40      1       [0.0022032 0.9977968]   0.002203226089477539
41      1       [0.0028597 0.9971403]   0.0028597116470336914
42      1       [0.00433764 0.9956624 ]         0.004337608814239502
43      0       [0.75701326 0.24298672]         0.2429867386817932
44      1       [0.00811706 0.9918829 ]         0.008117079734802246
45      1       [0.00291652 0.9970835 ]         0.0029165148735046387
46      1       [0.00290703 0.99709296]         0.0029070377349853516
47      0       [0.9977018  0.00229819]         0.0022981762886047363
48      1       [0.00179993 0.99820006]         0.001799941062927246
49      0       [0.99790084 0.00209914]         0.002099156379699707

================

Confusion matrix

================

        P       N
P       29      4
N       1       16
Precision: 0.9666666666666667
Recall: 0.8787878787878788

# TEST 4
sample  actual          predicted                       prediction error (over correct class)
0       0       [0.96634364 0.03365636]         0.03365635871887207
1       0       [0.99419904 0.00580101]         0.005800962448120117
2       1       [0.00326865 0.9967314 ]         0.003268599510192871
3       0       [0.9016363  0.09836372]         0.09836369752883911
4       0       [0.9808905  0.01910949]         0.019109487533569336
5       1       [0.00469815 0.99530184]         0.00469815731048584
6       0       [0.99790984 0.00209008]         0.002090156078338623
7       1       [0.00333679 0.99666315]         0.0033368468284606934
8       1       [0.06011737 0.9398826 ]         0.06011742353439331
9       1       [0.10515369 0.8948463 ]         0.10515367984771729
10      1       [0.00705993 0.99294007]         0.007059931755065918
11      1       [0.8086758  0.19132413]         **0.8086758702993393**
12      1       [0.00297699 0.99702305]         0.0029769539833068848
13      0       [0.81534725 0.18465275]         0.18465274572372437
14      0       [0.9973808  0.00261919]         0.0026192069053649902
15      0       [0.9804937  0.01950624]         0.01950627565383911
16      1       [0.0023799  0.99762005]         0.0023799538612365723
17      1       [0.00207583 0.9979241 ]         0.0020759105682373047
18      1       [0.00170067 0.9982993 ]         0.0017006993293762207
19      0       [0.9820807  0.01791931]         0.017919301986694336
20      0       [0.9714982  0.02850176]         0.028501808643341064
21      0       [0.97249705 0.02750287]         0.02750295400619507
22      1       [0.00339574 0.9966042 ]         0.0033957958221435547
23      1       [0.01510205 0.9848979 ]         0.015102088451385498
24      1       [0.0017865 0.9982135]   0.0017864704132080078
25      1       [0.00668555 0.99331445]         0.0066855549812316895
26      1       [0.00502491 0.9949751 ]         0.005024909973144531
27      0       [0.9949125  0.00508745]         0.005087494850158691
28      1       [0.00416768 0.9958324 ]         0.004167616367340088
29      1       [0.00399627 0.9960037 ]         0.003996312618255615
30      1       [0.00231737 0.9976826 ]         0.0023174285888671875
31      1       [0.00501267 0.99498737]         0.005012631416320801
32      0       [0.9336415  0.06635857]         0.06635850667953491
33      1       [0.0028214  0.99717855]         0.0028214454650878906
34      0       [0.96658796 0.03341202]         0.033412039279937744
35      0       [0.9895074  0.01049267]         0.01049262285232544
36      0       [0.99580824 0.00419172]         0.004191756248474121
37      1       [0.00181096 0.99818903]         0.0018109679222106934
38      0       [0.9851317  0.01486835]         0.014868319034576416
39      1       [0.00439921 0.9956008 ]         0.0043991804122924805
40      1       [0.00157937 0.9984206 ]         0.0015794038772583008
41      1       [0.01109959 0.9889004 ]         0.011099576950073242
42      0       [0.9629678  0.03703224]         0.03703218698501587
43      1       [0.00878484 0.9912151 ]         0.008784890174865723
44      1       [0.00163091 0.99836916]         0.0016308426856994629
45      1       [0.00429528 0.9957047 ]         0.004295289516448975
46      0       [0.9699618  0.03003816]         0.030038177967071533
47      0       [0.9643325  0.03566748]         0.035667479038238525
48      1       [0.01145342 0.9885466 ]         0.011453390121459961
49      0       [0.99757904 0.00242094]         0.002420961856842041

================

Confusion matrix

================

        P       N
P       28      1
N       0       21
Precision: 1.0
Recall: 0.9655172413793104

# TEST 5

sample  actual          predicted                       prediction error (over correct class)
0       0       [0.9980154  0.00198459]         0.0019845962524414062
1       0       [0.99537826 0.00462175]         0.004621744155883789
2       0       [0.6973826  0.30261734]         0.3026173710823059
3       1       [0.12079462 0.8792054 ]         0.12079459428787231
4       1       [0.00856548 0.9914346 ]         0.008565425872802734
5       0       [0.94634676 0.05365327]         0.05365324020385742
6       0       [0.9950807  0.00491928]         0.004919290542602539
7       1       [0.00297112 0.9970289 ]         0.0029711127281188965
8       0       [0.98364866 0.01635135]         0.01635134220123291
9       1       [0.00289238 0.9971077 ]         0.00289231538772583
10      0       [0.9693973 0.0306027]   0.030602693557739258
11      0       [0.75045    0.24954997]         0.2495499849319458
12      1       [0.00352206 0.9964779 ]         0.0035220980644226074
13      1       [0.10712324 0.89287674]         0.10712325572967529
14      0       [0.9877049  0.01229509]         0.012295126914978027
15      1       [0.00169275 0.9983072 ]         0.0016927719116210938
16      1       [0.14617796 0.85382205]         0.14617794752120972
17      1       [0.00356169 0.9964384 ]         0.0035616159439086914
18      0       [0.99563676 0.00436328]         0.00436323881149292
19      1       [0.08009249 0.9199075 ]         0.08009248971939087
20      1       [0.0104872  0.98951286]         0.010487139225006104
21      0       [0.9959709  0.00402906]         0.00402909517288208
22      1       [0.00763178 0.9923683 ]         0.00763171911239624
23      1       [0.00413393 0.99586606]         0.004133939743041992
24      0       [0.9981192 0.0018808]   0.0018808245658874512
25      0       [0.9829349  0.01706517]         0.017065107822418213
26      0       [0.98593664 0.01406344]         0.014063358306884766
27      1       [0.00171584 0.99828416]         0.00171583890914917
28      1       [0.0054613 0.9945387]   0.005461275577545166
29      1       [0.00212685 0.9978732 ]         0.0021268129348754883
30      1       [0.00187129 0.9981287 ]         0.0018712878227233887
31      0       [0.9963232  0.00367675]         0.003676772117614746
32      1       [0.00174039 0.9982596 ]         0.0017403960227966309
33      1       [0.00544837 0.9945516 ]         0.005448400974273682
34      0       [0.9973732  0.00262682]         0.002626776695251465
35      0       [0.98602825 0.01397176]         0.01397174596786499
36      1       [0.00189695 0.998103  ]         0.001896977424621582
37      0       [0.99386495 0.00613502]         0.006135046482086182
38      1       [0.00831777 0.9916822 ]         0.008317828178405762
39      0       [0.9959966  0.00400339]         0.004003405570983887
40      0       [0.99247956 0.00752045]         0.007520437240600586
41      0       [0.98528683 0.01471318]         0.014713168144226074
42      1       [0.00115909 0.998841  ]         0.0011590123176574707
43      0       [0.98081255 0.01918753]         0.019187450408935547
44      1       [0.0020918  0.99790823]         0.0020917654037475586
45      1       [0.00659604 0.993404  ]         0.006596028804779053
46      1       [0.0038831 0.9961169]   0.0038831233978271484
47      1       [0.29287437 0.70712566]         0.2928743362426758
48      1       [0.0034015  0.99659854]         0.003401458263397217
49      1       [0.04969347 0.9503066 ]         0.049693405628204346

================

Confusion matrix

================

        P       N
P       28      0
N       0       22
Precision: 1.0
Recall: 1.0

#TEST 6
sample  actual          predicted                       prediction error (over correct class)
0       1       [0.00340984 0.99659014]         0.003409862518310547
1       1       [0.00109899 0.998901  ]         0.0010989904403686523
2       1       [0.00196198 0.998038  ]         0.001962006092071533
3       0       [0.9899435 0.0100565]   0.010056495666503906
4       0       [0.99364257 0.00635746]         0.006357431411743164
5       0       [0.9709547  0.02904525]         0.029045283794403076
6       1       [0.00755117 0.9924488 ]         0.0075511932373046875
7       1       [0.00183183 0.9981681 ]         0.0018318891525268555
8       1       [0.0020963 0.9979037]   0.0020962953567504883
9       0       [0.98728484 0.01271509]         0.012715160846710205
10      1       [0.0346983 0.9653017]   0.034698307514190674
11      1       [0.00325668 0.9967434 ]         0.0032566189765930176
12      0       [0.9363357  0.06366435]         0.06366431713104248
13      1       [0.00319763 0.99680233]         0.0031976699829101562
14      1       [0.00281544 0.9971846 ]         0.002815425395965576
15      1       [0.00550102 0.994499  ]         0.005500972270965576
16      1       [0.0025528  0.99744725]         0.0025527477264404297
17      1       [0.00429395 0.995706  ]         0.004293978214263916
18      1       [0.00295642 0.99704355]         0.0029564499855041504
19      1       [0.00143349 0.99856657]         0.0014334321022033691
20      0       [0.99627614 0.00372393]         0.0037238597869873047
21      1       [0.00226345 0.9977366 ]         0.0022634267807006836
22      0       [0.95267993 0.04732004]         0.04732006788253784
23      1       [0.05828082 0.9417191 ]         0.058280885219573975
24      0       [0.98159903 0.01840093]         0.018400967121124268
25      1       [0.00789903 0.992101  ]         0.007898986339569092
26      1       [0.00214826 0.9978517 ]         0.002148270606994629
27      1       [0.00284641 0.9971535 ]         0.0028464794158935547
28      1       [0.02015213 0.97984785]         0.020152151584625244
29      1       [0.00625301 0.993747  ]         0.00625300407409668
30      0       [0.99815696 0.00184307]         0.0018430352210998535
31      0       [0.9920481  0.00795188]         0.007951915264129639
32      1       [0.00617863 0.9938214 ]         0.006178617477416992
33      0       [0.9968309  0.00316917]         0.003169119358062744
34      1       [0.00458382 0.99541616]         0.004583835601806641
35      1       [0.00625571 0.9937443 ]         0.006255686283111572
36      1       [0.00567412 0.9943258 ]         0.005674183368682861
37      0       [0.9975815  0.00241855]         0.00241851806640625
38      1       [0.04473708 0.95526296]         0.044737040996551514
39      1       [0.0082611 0.9917389]   0.00826108455657959
40      1       [0.00226244 0.9977375 ]         0.0022624731063842773
41      0       [0.9968561  0.00314392]         0.003143906593322754
42      1       [0.00189618 0.99810374]         0.0018962621688842773
43      0       [0.9971149  0.00288508]         0.002885103225708008
44      1       [0.00287953 0.9971205 ]         0.002879500389099121
45      0       [0.81317127 0.18682869]         0.18682873249053955
46      1       [0.00152147 0.9984786 ]         0.0015214085578918457
47      1       [0.00524363 0.99475634]         0.005243659019470215
48      1       [0.00330509 0.9966949 ]         0.00330507755279541
49      0       [0.99284184 0.00715812]         0.007158160209655762

================

Confusion matrix

================

        P       N
P       34      0
N       0       16
Precision: 1.0
Recall: 1.0

# TEST 7
sample  actual          predicted                       prediction error (over correct class)
0       0       [0.99056304 0.00943699]         0.009436964988708496
1       0       [0.9881045  0.01189554]         0.011895477771759033
2       0       [0.9965438  0.00345612]         0.0034561753273010254
3       0       [0.9931886  0.00681143]         0.006811380386352539
4       0       [0.97162694 0.02837303]         0.02837306261062622
5       0       [0.9873355 0.0126645]   0.012664496898651123
6       0       [0.990497   0.00950306]         0.009503006935119629
7       1       [0.01269155 0.98730844]         0.01269155740737915
8       0       [0.9812975  0.01870251]         0.01870250701904297
9       0       [0.9957723  0.00422773]         0.004227697849273682
10      0       [0.983285   0.01671499]         0.01671499013900757
11      0       [0.9710052  0.02899482]         0.02899479866027832
12      0       [0.9938699 0.0061301]   0.006130099296569824
13      1       [0.00224392 0.99775606]         0.002243936061859131
14      0       [0.99453473 0.00546524]         0.005465269088745117
15      0       [0.9854226  0.01457741]         0.014577388763427734
16      0       [0.9810604 0.0189396]   0.018939614295959473
17      0       [0.5981325  0.40186757]         **0.40186750888824463**
18      0       [0.9957475 0.0042525]   0.004252493381500244
19      1       [0.01810174 0.98189825]         0.018101751804351807
20      0       [0.986821   0.01317905]         0.013179004192352295
21      0       [0.9842218  0.01577822]         0.015778183937072754
22      0       [0.9963362  0.00366379]         0.003663778305053711
23      0       [0.9714807 0.0285192]   0.028519272804260254
24      1       [0.00416915 0.99583083]         0.004169166088104248
25      0       [0.9961047  0.00389535]         0.003895282745361328
26      1       [0.00543576 0.9945642 ]         0.005435824394226074
27      1       [0.0061815  0.99381846]         0.006181538105010986
28      0       [0.93364066 0.06635935]         0.06635934114456177
29      0       [0.9757699  0.02423014]         0.024230122566223145
30      0       [0.95148873 0.04851125]         0.04851126670837402
31      1       [0.00380058 0.9961994 ]         0.0038005709648132324
32      0       [0.99532133 0.00467869]         0.004678666591644287
33      1       [0.00442397 0.995576  ]         0.004423975944519043
34      1       [0.00123924 0.9987608 ]         0.001239180564880371
35      0       [0.9791988  0.02080127]         0.020801186561584473
36      0       [0.9791199  0.02088002]         0.02088010311126709
37      0       [0.99716467 0.00283528]         0.0028353333473205566
38      0       [0.9910665  0.00893353]         0.008933484554290771
39      1       [0.08446598 0.915534  ]         0.08446598052978516
40      1       [0.00311075 0.9968893 ]         0.0031107068061828613
41      1       [0.03316102 0.96683896]         0.033161044120788574
42      1       [0.00337284 0.9966272 ]         0.003372788429260254
43      1       [0.00408486 0.9959151 ]         0.004084885120391846
44      1       [0.00660723 0.99339277]         0.006607234477996826
45      0       [0.9971873  0.00281264]         0.002812683582305908
46      1       [0.00167031 0.9983297 ]         0.0016703009605407715
47      0       [0.99113816 0.00886184]         0.008861839771270752
48      1       [0.00299821 0.9970018 ]         0.002998173236846924
49      1       [0.0014618  0.99853826]         0.0014617443084716797

================

Confusion matrix

================

        P       N
P       18      0
N       1       31
Precision: 0.9473684210526315
Recall: 1.0